## TODO

[x] add a sleeve to hand
[x] hang stock off sleeve
[x] move stock wherever
[x] clone stock to built
[x] drop built
[x] fix white-screen
[x] use spawn entity
[x] save built as plan on server
[x] rebuild from server plan
[x] add some more cloneables
[x] turn off re-clone by default
[x] reshape hands to be sharper
[x] clean up to components
[x] scaling/resize
[x] axis stretching
[x] save plan with scale and rotation too
[x] add console to sleeve
[x] move up hands into view if not in quest
[x] global error handler
[x] local catch to log
[x] watch touched object on console
[x] allow grab console, retaining watch link
[x] exclude monitor consoles from plan save
[x] split resize out of grabber
[x] fix streching
[x] easier stretching
    - make axis lock margin greater at more distance
[x] move code around
[x] - extract collider wrapper for aabb-collider
[x] - extract toucher component - esp. from grabber - hands off events e.g. to grabber, monitor
[x] flick to clone
    [x] single clone
    [x] copy rotation and scale
    [x] easier to flick
[x] delete object
    [x] just move out of vision / behind back and release
    - lesser delete ideas
      - flick away with back of hand
      - make v small
      - splat it
      - tear it up
[x] change colour - inside sleeve
    [x] move to colour easier than rotation... r g b axes 
    [ ] (twist for shiny etc. ?)
    [ ] copy - take colour off sleeve and touch other objects with it
    - revert, re-apply - see undo?
[x] fix plan / build preserve rotation
[x] revert broken group reparenting
[x] unit tests to understand three.js transforms
[x] unit tests to prove aframe reparenting functions
[ ] tidy up collisions
    - collision monitor - showing closest and all current collisionsed :)
      - use identity of tag, color, scale
    - integration test for collisions?
[/] group
    [x] basic grouping attaching dropped entities to touched entities
    [x] world-placement maintaining reparenting
    [ ] clean up colliders (etc.?) for removed entities
    [ ] plan/build of nested entities
    [ ] vertical axis captured when group created
    [ ] use virtual twist-connectors for groups
        - align and twist-right to group
        - hold both and twist-left to ungroup
        - maybe interact direct with connectors to interact with group (options on sleeve)
        - shaded bounding box + ports - like clicking lego
[ ] ungroup
[ ] keyboard entry
    [x] create key tile with monitor, fires letter on collision with touchable
    [x] create key-home with a-z, space and linked monitor
    [x] use group to prototype hand typing attachments
    [x] custom keyboard mode when hand within keyboard space (auto-attach typist-hand)
    [x] remove sleeves when typing
    [x] whole keyboard pushed down by first contact, mitigating lack of physical stop, hopefully reducing second-typings
        - follow locked to y, offset by fingertip width
    [x] adjustable finger locations on typist-hand (normal in-group movement)
    [x] extend fingers on rotate around z (discrete)
    [x] extend fingers smoothly in proportion to rotation
    [x] try 4 fingers - yeah, maybe?
    [ ] make push-down more positive
        [ ] work from location of fingertip, not by grabbing its offset at first contact
        [ ] add tapping sound to keyboard
    [ ] draggable keyboard
    [ ] resizable keyboard
    [ ] reintroduce thumb - back for space?
    [ ] adjustable finger locations on typist-hand without breaking extension (lock in-group)
        - dev-mode / activate switch on contact (on arm)
    [ ] easy adjust parameters: hand rotation vs fingers, span, amount of travel etc.
    [ ] numbers and syntax keys
    [ ] edit - grabbable handle moves with cursor?
    [ ] auto-complete (hovers above?)
[ ] arm takeover
    - object information
    - object actions
    - animated takeover for clarity - square flips?
[ ] alternative actions
    - ambiguous inputs
    - clear and easy way to choose intent:
      - in physical space, close to actions
      - in predicatble way, so can intuitively short-cut
[ ] undelete - grab behind back and bring it out (stack...  undo?)
[ ] default align vertical
    - show avatar (transparent) for align, move through it to 'pick it up' and turn on alignment 
[ ] align to objects
    - objects provide viscous resistance when you push another object into them?
      - within margin just rests on surface / aligns to surface?
      - pushing with second hand reduces viscosity?
      - distance offset from object to hand denotes force on object
    - avatar appears on objects as you get near?
[ ] multiple plans
    - use shapes as plan keys
    - drag on/off like glasses?
    - ultimately add other shapes to the keys (as group) to build little representations for plans
    - the starting room can be built as you see fit to organise your plan keys
    - maybe ultimately add plan keys within any plan
[ ] switch custom handler code to host.emit() events and addEventListener...
[ ] unit tests on copyPlacement() / applyPlacement()
[ ] texture browser...
    - 3d movement with axes for roughness etc
    - areas in globes are different 'topics'
    - areas are like graph with weighted connections
[ ] focus (see below) to break alignment (focus == concentrating on fine placement)
[ ] align to axis - inside sleeve? 
    ... or maybe alignment by how far away other hand is...
    ... move hand far away is coarse grid and align, closer to is finer grid (visible affordance)
    ... once relationship with other hand formed, rotation of hand affects axis-alignment lock?
    ... rumble other hand as pass gridline to gridline, to denote relationship
[ ] fix TODOs
[ ] remove unwanted parent dereferencing between model<->hand
    - and yet allow scriptable movement - factor out oculus hand control
    - use local<->world conversions
[ ] recorder component
[ ] playback - 
[ ] slow replay for debugging (e.g. tuning flick)
[ ] re-use a tick-interval updater for performance
    - tracking doesn't have to be frame by frame for many things
    - search for tickCount (used for mod tick selection)
[ ] improve grab location - re-parent or track orientation / vector offset?
[ ] control clone vs move ??
    - single grab == move
    - double grab = stretch
    - touch and grab = clone
    - or maybe for clone, grab and pull through other hand (other hand holding original in place)
[ ] split out lower doc pieces (testing) in this todo to readme/doc
[ ] properly shape hands
[ ] have proper focus events
    - focus as scalar quantity
    - based on looking at something
    - greater value more directly you're looking at it
    - ramps up with time, up to a limit based on centrality
    - intention is to bring in more options and data as focus increases
[ ] monitor points to thing being monitored (on focus / touch monitor?)
[ ] remote chrome debugging?
[/] fix debug
[ ] decent log console
  - like files in a cabinet - see start of each as you flick hand through
  - can move and bin off groups
  - maybe with filtering (select fixed bit of text to group)
  - group with tabs maybe
[ ] stretch improvements
    - apply on per-geometry basis, or use other mechanisms to limit non-unifrom scaling, as three.js
      does not support non-uniform scaling (https://github.com/mrdoob/three.js/issues/3845)
      resulting in shear transformations on children of non-uniform-scaled parents
    - axis lock affordance
    - finer grained control at small margins
[ ] visual clone-flick debug (for tweaking activation)
    - color over limits
    - visual gauge showing countdown timer
    - little graph

- undo
  [ ] do as command object
  [ ] show command stack - drag rope/chain of events from behind back
  [ ] undos flow from actions slowly in space, so:
      - you can see what happened
      - you can very quickly grab it and re-apply for v quick undo
      - by moving behind user, it gives affordance that that's where history goes
  [ ] activate undo
  [ ] undo rope coils together movements etc into spirals (rotate to move through)
      without using so much rope/chain length
[ ] visual debug gauge to show scalars


### unit testing components

[ ] try ngokevin pattern
[ ] split out 'part' - and part-component adapter - to simply unit test part


### in-vr testing

isolated unit testing are basically already covered, e.g. mocha tests in
browser, and accessing or integrating into vr environment isn't bringing
anything extra at this level (though in trying to understand interaction 
unit tests might, vr visualisations might be useful)

so it's really about integration and functional testing, so how cool would
it be to:

[ ] create plan basis for test
[ ] record actions (of actors e.g. hands)
[ ] capture result state (final plan + actor state)
[ ] reload plan and playback actions
[ ] assert on aspects of result state
  - codeless
    - match selected attributes, perhaps with range (e.g. x matches +- 0.01)
    - wait for asserts to pass, or timeout
  - with code
    - load named plan
    - play named action recording
    - use specific coded asserts
    - replace or augment named plan with scene building
    - replace or augment actions with code-specified actions e.g. leftHand.moveTo(cube1, rate: 1).grab()
    
